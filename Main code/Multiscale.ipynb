{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia Nemo\n",
    "Neural Diarizer: Multiscale Diarization Decoder with Oracle VAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 12:35:39 nemo_logging:349] c:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from nemo.collections.asr.parts.utils.speaker_utils import (\n",
    "    rttm_to_labels,\n",
    "    labels_to_pyannote_object,\n",
    ")\n",
    "import os\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.collections.asr.models import ClusteringDiarizer\n",
    "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "\n",
    "import wget\n",
    "import json\n",
    "import nemo.utils\n",
    "\n",
    "nemo_logger = nemo.utils.logging\n",
    "nemo_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.35it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.53it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.17it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.01it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.24it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.99it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.18it/s]/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.12s/it]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.32it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.76it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.66it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]s/it]\n",
      " 10%|█         | 22/216 [20:11<3:43:22, 69.09s/it]"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "data_directory = \"../Dataset/Audio/Dev\"\n",
    "rttm_directory = \"../Dataset/RTTMs/Dev\"\n",
    "sr = 16000\n",
    "results_directory = \"../Results/Oracle_Decoder\"\n",
    "model_config = \"../Config/\"\n",
    "Metadata_test = \"../Metadata_test/\"\n",
    "logging.getLogger(\"nemo\").setLevel(logging.ERROR)\n",
    "\n",
    "# Loading the pre-trained model\n",
    "MODEL_CONFIG = os.path.join(model_config, \"diar_infer_telephonic.yaml\")\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    print(\"Did not find the model config file, downloading it now\")\n",
    "    config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_telephonic.yaml\"\n",
    "    MODEL_CONFIG = wget.download(config_url, model_config)\n",
    "\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "pretrained_speaker_model = \"titanet_large\"\n",
    "config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [\n",
    "    1.5,\n",
    "    1.25,\n",
    "    1.0,\n",
    "    0.75,\n",
    "    0.5,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [\n",
    "    0.75,\n",
    "    0.625,\n",
    "    0.5,\n",
    "    0.375,\n",
    "    0.1,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.multiscale_weights = [1, 1, 1, 1, 1]\n",
    "config.diarizer.oracle_vad = True  # ----> ORACLE VAD\n",
    "config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "config.device = \"cuda\"\n",
    "config.diarizer.out_dir = results_directory  # Set out_dir correctly\n",
    "config.diarizer.output_dir = results_directory\n",
    "config.diarizer.msdd_model.model_path = (\n",
    "    \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
    ")\n",
    "config.diarizer.msdd_model.parameters.sigmoid_threshold = [\n",
    "    0.7,\n",
    "    1.0,\n",
    "]  # Evaluate with T=0.7 and T=1.0\n",
    "\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in tqdm(os.listdir(data_directory)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Get the file paths\n",
    "        audio_path = os.path.join(data_directory, filename)\n",
    "        # Get the RTTM file path. They are are ../Dataset/RTTMs/Dev\n",
    "        rttm_path = os.path.join(rttm_directory, filename.replace(\".wav\", \".rttm\"))\n",
    "        signal, sr = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "        # Get the labels from the RTTM file\n",
    "        labels = rttm_to_labels(rttm_path)\n",
    "        reference = labels_to_pyannote_object(labels)\n",
    "\n",
    "        # Create the metadata dictionary\n",
    "        meta = {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"offset\": 0,\n",
    "            \"duration\": None,\n",
    "            \"label\": \"infer\",\n",
    "            \"text\": \"-\",\n",
    "            \"num_speakers\": None,\n",
    "            \"rttm_filepath\": rttm_path,\n",
    "            \"uem_filepath\": None,\n",
    "        }\n",
    " \n",
    "        # Write the metadata to a JSON file\n",
    "        manifest_filename = filename.replace(\".wav\", \".json\")\n",
    "        manifest_path = os.path.join(Metadata_test, manifest_filename)\n",
    "        with open(manifest_path, \"w\") as fp:\n",
    "            json.dump(meta, fp)\n",
    "            fp.write(\"\\n\")\n",
    "\n",
    "        config.diarizer.manifest_filepath = (\n",
    "            manifest_path  # Use the correct manifest path\n",
    "        )\n",
    "        oracle_vad_msdd_model = NeuralDiarizer(cfg=config)\n",
    "        oracle_vad_msdd_model.diarize()\n",
    "    \n",
    "        # Get the RTTMS\n",
    "        rttm_pred_path = os.path.join(results_directory, \"pred_rttms\", filename.replace(\".wav\", \".rttm\"))\n",
    "        pred_labels_neural = rttm_to_labels(rttm_pred_path)\n",
    "\n",
    "        # Refresh the cuda memory\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
