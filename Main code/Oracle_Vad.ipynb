{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia Nemo\n",
    "In this code we run Nvidia Nemo on all of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:15 nemo_logging:349] c:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from nemo.collections.asr.parts.utils.speaker_utils import (\n",
    "    rttm_to_labels,\n",
    "    labels_to_pyannote_object,\n",
    ")\n",
    "import os\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.collections.asr.models import ClusteringDiarizer\n",
    "\n",
    "\n",
    "import wget\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:18 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2024-05-30 13:21:18 cloud:58] Found existing object C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n",
      "[NeMo I 2024-05-30 13:21:18 cloud:64] Re-using file from: C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo\n",
      "[NeMo I 2024-05-30 13:21:18 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:18 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-30 13:21:18 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:18 features:305] PADDING: 16\n",
      "[NeMo I 2024-05-30 13:21:19 save_restore_connector:263] Model EncDecSpeakerLabelModel was successfully restored from C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n",
      "[NeMo I 2024-05-30 13:21:19 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-05-30 13:21:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale0.json\n",
      "[NeMo I 2024-05-30 13:21:19 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:19 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:19 collections:733] Dataset loaded with 82 items, total duration of  0.03 hours.\n",
      "[NeMo I 2024-05-30 13:21:19 collections:735] # 82 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale1.json\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:20 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:733] Dataset loaded with 99 items, total duration of  0.03 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:735] # 99 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale2.json\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:20 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:733] Dataset loaded with 124 items, total duration of  0.03 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:735] # 124 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale3.json\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:20 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:733] Dataset loaded with 166 items, total duration of  0.03 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:735] # 166 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale4.json\n",
      "[NeMo I 2024-05-30 13:21:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:20 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:733] Dataset loaded with 619 items, total duration of  0.09 hours.\n",
      "[NeMo I 2024-05-30 13:21:20 collections:735] # 619 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:21 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:21 clustering_diarizer:464] Outputs are saved in c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Results\\Oracle_vad directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:21 nemo_logging:349] c:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\pyannote\\metrics\\utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:21 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap True: \n",
      "     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0000\t, Confusion ER:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/216 [00:04<14:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:21 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2024-05-30 13:21:21 cloud:58] Found existing object C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n",
      "[NeMo I 2024-05-30 13:21:21 cloud:64] Re-using file from: C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo\n",
      "[NeMo I 2024-05-30 13:21:21 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:22 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-30 13:21:22 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:22 features:305] PADDING: 16\n",
      "[NeMo I 2024-05-30 13:21:22 save_restore_connector:263] Model EncDecSpeakerLabelModel was successfully restored from C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:22 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:22 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-05-30 13:21:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale0.json\n",
      "[NeMo I 2024-05-30 13:21:22 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:22 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:22 collections:733] Dataset loaded with 154 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-30 13:21:22 collections:735] # 154 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale1.json\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:23 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:733] Dataset loaded with 184 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:735] # 184 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale2.json\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:23 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:733] Dataset loaded with 233 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:735] # 233 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale3.json\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:23 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:733] Dataset loaded with 318 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:735] # 318 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale4.json\n",
      "[NeMo I 2024-05-30 13:21:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:23 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:733] Dataset loaded with 1136 items, total duration of  0.16 hours.\n",
      "[NeMo I 2024-05-30 13:21:23 collections:735] # 1136 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:24 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:25 clustering_diarizer:464] Outputs are saved in c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Results\\Oracle_vad directory\n",
      "[NeMo I 2024-05-30 13:21:25 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap True: \n",
      "     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0000\t, Confusion ER:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/216 [00:07<12:49,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:25 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2024-05-30 13:21:25 cloud:58] Found existing object C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n",
      "[NeMo I 2024-05-30 13:21:25 cloud:64] Re-using file from: C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo\n",
      "[NeMo I 2024-05-30 13:21:25 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:25 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-30 13:21:25 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:25 features:305] PADDING: 16\n",
      "[NeMo I 2024-05-30 13:21:26 save_restore_connector:263] Model EncDecSpeakerLabelModel was successfully restored from C:\\Users\\rakin\\.cache\\torch\\NeMo\\NeMo_2.0.0rc1\\titanet-l\\11ba0924fdf87c049e339adbf6899d48\\titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-30 13:21:26 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-30 13:21:26 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-05-30 13:21:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale0.json\n",
      "[NeMo I 2024-05-30 13:21:26 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:26 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:26 collections:733] Dataset loaded with 875 items, total duration of  0.36 hours.\n",
      "[NeMo I 2024-05-30 13:21:26 collections:735] # 875 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:26 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale1.json\n",
      "[NeMo I 2024-05-30 13:21:26 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:26 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:26 collections:733] Dataset loaded with 1048 items, total duration of  0.36 hours.\n",
      "[NeMo I 2024-05-30 13:21:26 collections:735] # 1048 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:27 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale2.json\n",
      "[NeMo I 2024-05-30 13:21:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:27 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:27 collections:733] Dataset loaded with 1311 items, total duration of  0.36 hours.\n",
      "[NeMo I 2024-05-30 13:21:27 collections:735] # 1311 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:28 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale3.json\n",
      "[NeMo I 2024-05-30 13:21:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:28 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:28 collections:733] Dataset loaded with 1752 items, total duration of  0.36 hours.\n",
      "[NeMo I 2024-05-30 13:21:28 collections:735] # 1752 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-05-30 13:21:29 clustering_diarizer:389] Saved embedding files to ../Results/Oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-30 13:21:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, ../Results/Oracle_vad\\speaker_outputs\\subsegments_scale4.json\n",
      "[NeMo I 2024-05-30 13:21:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-30 13:21:29 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-30 13:21:29 collections:733] Dataset loaded with 6537 items, total duration of  0.91 hours.\n",
      "[NeMo I 2024-05-30 13:21:29 collections:735] # 6537 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/216 [00:12<22:49,  6.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m\n\u001b[0;32m     72\u001b[0m config\u001b[38;5;241m.\u001b[39mdiarizer\u001b[38;5;241m.\u001b[39mmanifest_filepath \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     73\u001b[0m     manifest_path  \u001b[38;5;66;03m# Use the correct manifest path\u001b[39;00m\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     75\u001b[0m oracle_vad_clusdiar_model \u001b[38;5;241m=\u001b[39m ClusteringDiarizer(cfg\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m---> 76\u001b[0m \u001b[43moracle_vad_clusdiar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Get the RTTMS\u001b[39;00m\n\u001b[0;32m     79\u001b[0m rttm_pred_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_rttms\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.rttm\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\nemo\\collections\\asr\\models\\clustering_diarizer.py:447\u001b[0m, in \u001b[0;36mClusteringDiarizer.diarize\u001b[1;34m(self, paths2audio_files, batch_size)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_segmentation(window, shift, scale_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_scale\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# Embedding Extraction for the current scale (scale_idx)\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsegments_manifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_embeddings_and_timestamps[scale_idx] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_stamps]\n\u001b[0;32m    451\u001b[0m embs_and_timestamps \u001b[38;5;241m=\u001b[39m get_embs_and_timestamps(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_embeddings_and_timestamps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_args_dict\n\u001b[0;32m    453\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\nemo\\collections\\asr\\models\\clustering_diarizer.py:350\u001b[0m, in \u001b[0;36mClusteringDiarizer._extract_embeddings\u001b[1;34m(self, manifest_file, scale_idx, num_scales)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_stamps \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    349\u001b[0m all_embs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_model\u001b[38;5;241m.\u001b[39mtest_dataloader(),\n\u001b[0;32m    352\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_scales\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] extract embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    353\u001b[0m     leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    355\u001b[0m ):\n\u001b[0;32m    356\u001b[0m     test_batch \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_model\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m test_batch]\n\u001b[0;32m    357\u001b[0m     audio_signal, audio_signal_len, labels, slices \u001b[38;5;241m=\u001b[39m test_batch\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\tqdm\\std.py:1169\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\nemo\\collections\\asr\\data\\audio_to_label.py:328\u001b[0m, in \u001b[0;36m_AudioLabelDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 328\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m f, fl \u001b[38;5;241m=\u001b[39m features, torch\u001b[38;5;241m.\u001b[39mtensor(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_regression_task:\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\nemo\\collections\\asr\\parts\\preprocessing\\features.py:202\u001b[0m, in \u001b[0;36mWaveformFeaturizer.process\u001b[1;34m(self, file_path, offset, duration, trim, trim_ref, trim_top_db, trim_frame_length, trim_hop_length, orig_sr, channel_selector, normalize_db)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    190\u001b[0m     file_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m     normalize_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    201\u001b[0m ):\n\u001b[1;32m--> 202\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mint_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrim_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrim_top_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_top_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrim_frame_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_frame_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrim_hop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_hop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_segment(audio)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\nemo\\collections\\asr\\parts\\preprocessing\\segment.py:239\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, audio_file, target_sr, int_values, offset, duration, trim, trim_ref, trim_top_db, trim_frame_length, trim_hop_length, orig_sr, channel_selector, normalize_db, ref_channel)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio_file, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(audio_file)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m sf_supported_formats:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    240\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m int_values \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    241\u001b[0m             sample_rate \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\soundfile.py:1193\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the appropriate sf_open*() function from libsndfile.\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (_unicode, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_os\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile exists: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "data_directory = \"../Dataset/Audio/Dev\"\n",
    "rttm_directory = \"../Dataset/RTTMs/Dev\"\n",
    "sr = 16000\n",
    "results_directory = \"../Results/Oracle_vad\"\n",
    "model_config = \"../Config/\"\n",
    "Metadata_test = \"../Metadata_test/\"\n",
    "\n",
    "# Loading the pre-trained model\n",
    "MODEL_CONFIG = os.path.join(model_config, \"diar_infer_telephonic.yaml\")\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    print(\"Did not find the model config file, downloading it now\")\n",
    "    config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_telephonic.yaml\"\n",
    "    MODEL_CONFIG = wget.download(config_url, model_config)\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "pretrained_speaker_model = \"titanet_large\"\n",
    "config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [\n",
    "    1.5,\n",
    "    1.25,\n",
    "    1.0,\n",
    "    0.75,\n",
    "    0.5,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [\n",
    "    0.75,\n",
    "    0.625,\n",
    "    0.5,\n",
    "    0.375,\n",
    "    0.1,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.multiscale_weights = [1, 1, 1, 1, 1]\n",
    "config.diarizer.oracle_vad = True  # ----> ORACLE VAD\n",
    "config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "config.device = \"cuda\"\n",
    "config.diarizer.out_dir = results_directory  # Set out_dir correctly\n",
    "config.diarizer.output_dir = results_directory\n",
    "\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in tqdm(os.listdir(data_directory)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Get the file paths\n",
    "        audio_path = os.path.join(data_directory, filename)\n",
    "        # Get the RTTM file path. They are are ../Dataset/RTTMs/Dev\n",
    "        rttm_path = os.path.join(rttm_directory, filename.replace(\".wav\", \".rttm\"))\n",
    "        signal, sr = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "        # Get the labels from the RTTM file\n",
    "        labels = rttm_to_labels(rttm_path)\n",
    "        reference = labels_to_pyannote_object(labels)\n",
    "\n",
    "        # Create the metadata dictionary\n",
    "        meta = {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"offset\": 0,\n",
    "            \"duration\": None,\n",
    "            \"label\": \"infer\",\n",
    "            \"text\": \"-\",\n",
    "            \"num_speakers\": None,\n",
    "            \"rttm_filepath\": rttm_path,\n",
    "            \"uem_filepath\": None,\n",
    "        }\n",
    "\n",
    "        # Write the metadata to a JSON file\n",
    "        manifest_filename = filename.replace(\".wav\", \".json\")\n",
    "        manifest_path = os.path.join(Metadata_test, manifest_filename)\n",
    "        with open(manifest_path, \"w\") as fp:\n",
    "            json.dump(meta, fp)\n",
    "            fp.write(\"\\n\")\n",
    "\n",
    "        config.diarizer.manifest_filepath = (\n",
    "            manifest_path  # Use the correct manifest path\n",
    "        )\n",
    "        oracle_vad_clusdiar_model = ClusteringDiarizer(cfg=config)\n",
    "        oracle_vad_clusdiar_model.diarize()\n",
    "\n",
    "        # Get the RTTMS\n",
    "        rttm_pred_path = os.path.join(results_directory, \"pred_rttms\", filename.replace(\".wav\", \".rttm\"))\n",
    "        pred_labels_neural = rttm_to_labels(rttm_pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
