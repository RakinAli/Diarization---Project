{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: aepyx.wav\n",
      "Processing file: aggyz.wav\n",
      "Processing file: aiqwk.wav\n",
      "Processing file: aorju.wav\n",
      "Processing file: auzru.wav\n",
      "Processing file: bgvvt.wav\n",
      "Processing file: bidnq.wav\n",
      "Processing file: bjruf.wav\n",
      "Processing file: bmsyn.wav\n",
      "Processing file: bpzsc.wav\n",
      "Processing file: bvqnu.wav\n",
      "Processing file: bvyvm.wav\n",
      "Processing file: bxcfq.wav\n",
      "Processing file: byapz.wav\n",
      "Processing file: cadba.wav\n",
      "Processing file: cawnd.wav\n",
      "Processing file: clfcg.wav\n",
      "Processing file: cpebh.wav\n",
      "Processing file: cqfmj.wav\n",
      "Processing file: crorm.wav\n",
      "Processing file: crylr.wav\n",
      "Processing file: cvofp.wav\n",
      "Processing file: cwbvu.wav\n",
      "Processing file: dgvwu.wav\n",
      "Processing file: diysk.wav\n",
      "Processing file: dkabn.wav\n",
      "Processing file: dlast.wav\n",
      "Processing file: dohag.wav\n",
      "Processing file: duvox.wav\n",
      "Processing file: dxbbt.wav\n",
      "Processing file: dxokr.wav\n",
      "Processing file: dzsef.wav\n",
      "Processing file: dzxut.wav\n",
      "Processing file: eauve.wav\n",
      "Processing file: eazeq.wav\n",
      "Processing file: eddje.wav\n",
      "Processing file: eguui.wav\n",
      "Processing file: eoyaz.wav\n",
      "Processing file: epygx.wav\n",
      "Processing file: eqsta.wav\n",
      "Processing file: erslt.wav\n",
      "Processing file: eucfa.wav\n",
      "Processing file: euqef.wav\n",
      "Processing file: ezxso.wav\n",
      "Processing file: fijfi.wav\n",
      "Processing file: fowhl.wav\n",
      "Processing file: fpfvy.wav\n",
      "Processing file: fqrnu.wav\n",
      "Processing file: fuzfh.wav\n",
      "Processing file: fvhrk.wav\n",
      "Processing file: fxnwf.wav\n",
      "Processing file: fyqoe.wav\n",
      "Processing file: fzwtp.wav\n",
      "Processing file: gcfwp.wav\n",
      "Processing file: gcvrb.wav\n",
      "Processing file: gfneh.wav\n",
      "Processing file: gkiki.wav\n",
      "Processing file: gmmwm.wav\n",
      "Processing file: gtjow.wav\n",
      "Processing file: gtnjb.wav\n",
      "Processing file: gukoa.wav\n",
      "Processing file: guvqf.wav\n",
      "Processing file: gwloo.wav\n",
      "Processing file: gylzn.wav\n",
      "Processing file: gyomp.wav\n",
      "Processing file: gzhwb.wav\n",
      "Processing file: hcyak.wav\n",
      "Processing file: heolf.wav\n",
      "Processing file: hhepf.wav\n",
      "Processing file: hqhrb.wav\n",
      "Processing file: iabca.wav\n",
      "Processing file: iacod.wav\n",
      "Processing file: ibrnm.wav\n",
      "Processing file: ifwki.wav\n",
      "Processing file: iiprr.wav\n",
      "Processing file: ikhje.wav\n",
      "Processing file: iowob.wav\n",
      "Processing file: isrps.wav\n",
      "Processing file: isxwc.wav\n",
      "Processing file: jbowg.wav\n",
      "Processing file: jdrwl.wav\n",
      "Processing file: jeymh.wav\n",
      "Processing file: jgiyq.wav\n",
      "Processing file: jjkrt.wav\n",
      "Processing file: jjvkx.wav\n",
      "Processing file: jrfaz.wav\n",
      "Processing file: jsbdo.wav\n",
      "Processing file: jsymf.wav\n",
      "Processing file: jttar.wav\n",
      "Processing file: jwggf.wav\n",
      "Processing file: jxpom.wav\n",
      "Processing file: jxydp.wav\n",
      "Processing file: jzkzt.wav\n",
      "Processing file: kajfh.wav\n",
      "Processing file: kgjaa.wav\n",
      "Processing file: kmjvh.wav\n",
      "Processing file: kmunk.wav\n",
      "Processing file: kpjud.wav\n",
      "Processing file: ktvto.wav\n",
      "Processing file: kvkje.wav\n",
      "Processing file: kzmyi.wav\n",
      "Processing file: laoyl.wav\n",
      "Processing file: lbfnx.wav\n",
      "Processing file: ledhe.wav\n",
      "Processing file: leneg.wav\n",
      "Processing file: lhuly.wav\n",
      "Processing file: lilfy.wav\n",
      "Processing file: ljpes.wav\n",
      "Processing file: lkikz.wav\n",
      "Processing file: lpola.wav\n",
      "Processing file: lscfc.wav\n",
      "Processing file: ltgmz.wav\n",
      "Processing file: lubpm.wav\n",
      "Processing file: luobn.wav\n",
      "Processing file: mbzht.wav\n",
      "Processing file: mclsr.wav\n",
      "Processing file: mhwyr.wav\n",
      "Processing file: mjmgr.wav\n",
      "Processing file: mkhie.wav\n",
      "Processing file: mqtep.wav\n",
      "Processing file: msbyq.wav\n",
      "Processing file: mupzb.wav\n",
      "Processing file: mxdpo.wav\n",
      "Processing file: mxduo.wav\n",
      "Processing file: myjoe.wav\n",
      "Processing file: neiye.wav\n",
      "Processing file: nitgx.wav\n",
      "Processing file: nkqzr.wav\n",
      "Processing file: nlvdr.wav\n",
      "Processing file: nprxc.wav\n",
      "Processing file: nqcpi.wav\n",
      "Processing file: nqyqm.wav\n",
      "Processing file: ocfop.wav\n",
      "Processing file: ofbxh.wav\n",
      "Processing file: olzkb.wav\n",
      "Processing file: ooxlj.wav\n",
      "Processing file: optsn.wav\n",
      "Processing file: oqwpd.wav\n",
      "Processing file: otmpf.wav\n",
      "Processing file: oubab.wav\n",
      "Processing file: ouvtt.wav\n",
      "Processing file: pccww.wav\n",
      "Processing file: pgtkk.wav\n",
      "Processing file: pkwrt.wav\n",
      "Processing file: poucc.wav\n",
      "Processing file: ppexo.wav\n",
      "Processing file: ptses.wav\n",
      "Processing file: pwnsw.wav\n",
      "Processing file: pxqme.wav\n",
      "Processing file: pzxit.wav\n",
      "Processing file: qadia.wav\n",
      "Processing file: qajyo.wav\n",
      "Processing file: qeejz.wav\n",
      "Processing file: qlrry.wav\n",
      "Processing file: qoarn.wav\n",
      "Processing file: qwepo.wav\n",
      "Processing file: qxana.wav\n",
      "Processing file: ralnu.wav\n",
      "Processing file: rarij.wav\n",
      "Processing file: rmvsh.wav\n",
      "Processing file: rpkso.wav\n",
      "Processing file: rsypp.wav\n",
      "Processing file: rxulz.wav\n",
      "Processing file: ryken.wav\n",
      "Processing file: sbrmv.wav\n",
      "Processing file: sebyw.wav\n",
      "Processing file: sexgc.wav\n",
      "Processing file: sfdvy.wav\n",
      "Processing file: svxzm.wav\n",
      "Processing file: swbnm.wav\n",
      "Processing file: sxqvt.wav\n",
      "Processing file: tbjqx.wav\n",
      "Processing file: thnuq.wav\n",
      "Processing file: tiido.wav\n",
      "Processing file: tkhgs.wav\n",
      "Processing file: tkybe.wav\n",
      "Processing file: tnjoh.wav\n",
      "Processing file: tpnyf.wav\n",
      "Processing file: tpslg.wav\n",
      "Processing file: tvtoe.wav\n",
      "Processing file: uedkc.wav\n",
      "Processing file: uevxo.wav\n",
      "Processing file: uhfrw.wav\n",
      "Processing file: uicid.wav\n",
      "Processing file: upshw.wav\n",
      "Processing file: uqxlg.wav\n",
      "Processing file: usqam.wav\n",
      "Processing file: utial.wav\n",
      "Processing file: vdlvr.wav\n",
      "Processing file: vgaez.wav\n",
      "Processing file: vgevv.wav\n",
      "Processing file: vncid.wav\n",
      "Processing file: vtzqw.wav\n",
      "Processing file: vuewy.wav\n",
      "Processing file: vylyk.wav\n",
      "Processing file: vzuru.wav\n",
      "Processing file: wcxfk.wav\n",
      "Processing file: wdvva.wav\n",
      "Processing file: wemos.wav\n",
      "Processing file: wibky.wav\n",
      "Processing file: wlfsf.wav\n",
      "Processing file: wprog.wav\n",
      "Processing file: wwvcs.wav\n",
      "Processing file: wwzsk.wav\n",
      "Processing file: xffsa.wav\n",
      "Processing file: xggbk.wav\n",
      "Processing file: xkgos.wav\n",
      "Processing file: xkmqx.wav\n",
      "Processing file: xlsme.wav\n",
      "Processing file: xlyov.wav\n",
      "Processing file: xmyyy.wav\n",
      "Processing file: xqxkt.wav\n",
      "Processing file: xtdcl.wav\n",
      "Processing file: xtzoq.wav\n",
      "Processing file: xvxwv.wav\n",
      "Processing file: ybhwz.wav\n",
      "Processing file: ygrip.wav\n",
      "Processing file: ylgug.wav\n",
      "Processing file: ylzez.wav\n",
      "Processing file: ytmef.wav\n",
      "Processing file: ytula.wav\n",
      "Processing file: yukhy.wav\n",
      "Processing file: yzvon.wav\n",
      "Processing file: zedtj.wav\n",
      "Processing file: zehzu.wav\n",
      "Processing file: zfzlc.wav\n",
      "Processing file: zowse.wav\n",
      "Processing file: zqidv.wav\n",
      "Processing file: zsgto.wav\n",
      "Processing file: zzsba.wav\n",
      "Processing file: zztbo.wav\n",
      "Processing file: zzyyo.wav\n"
     ]
    }
   ],
   "source": [
    "# All imports\n",
    "import librosa\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_vad import (\n",
    "    get_speech_timestamps,\n",
    ")  # Assuming this file defines the get_speech_timestamps function\n",
    "from preprocess import Wav2Mel\n",
    "import torchaudio\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mode\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=UserWarning,\n",
    "    message=\"RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\",\n",
    ")\n",
    "\n",
    "\n",
    "# Global variables used for preprocessing\n",
    "SAMPLE_RATE = 16000\n",
    "NORM_DB = -3\n",
    "FFT_WINDOW_MS = 25\n",
    "FFT_HOP_MS = 10\n",
    "FRAME_SIZE = 40  # Adjust frame size if needed\n",
    "BLOCK_SIZE = 50  # MFCC frames to stack together for embedding\n",
    "\n",
    "# Path to audio file\n",
    "TEST_PATH = \"../Dataset/Audio/Test/\"\n",
    "OUTPUT_PATH = \"../Results/Custom Pipeline/\"\n",
    "\n",
    "# Load the models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dvector_model = torch.jit.load(\"Pretrained Modules/dvector-step250000.pt\")\n",
    "dvector_model = dvector_model.to(device)\n",
    "vad_model = torch.jit.load(\"Pretrained Modules/silero_vad.jit\")\n",
    "vad_model = vad_model.to(device)\n",
    "wave2mel = Wav2Mel(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    norm_db=NORM_DB,\n",
    "    fft_window_ms=FFT_WINDOW_MS,\n",
    "    fft_hop_ms=FFT_HOP_MS,\n",
    "    n_mels=40,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dvector_model.to(device)\n",
    "\n",
    "\n",
    "def convert_samples_to_time(segments, sampling_rate):\n",
    "    time_segments = []\n",
    "    for segment in segments:\n",
    "        start_time = segment[\"start\"] / sampling_rate\n",
    "        end_time = segment[\"end\"] / sampling_rate\n",
    "        time_segments.append({\"start\": start_time, \"end\": end_time})\n",
    "    return time_segments\n",
    "\n",
    "\n",
    "def get_frames(mel_tensor, block_size):\n",
    "    return mel_tensor.unfold(0, block_size, block_size).mT\n",
    "\n",
    "\n",
    "def get_frame_embeddings(mel_frames):\n",
    "    embeddings = torch.empty(mel_frames.shape[0], 256, device=device)\n",
    "    for frame_idx in range(mel_frames.shape[0]):\n",
    "        frame = mel_frames[frame_idx].to(device)  # Move the frame to the GPU\n",
    "        embeddings[frame_idx, :] = dvector_model.embed_utterance(frame)\n",
    "    return embeddings.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def normalized_laplacian_matrix(A):\n",
    "    # A is an adjacency matrix\n",
    "    D = np.sum(A, axis=1)\n",
    "    inv_sqrt_D = np.power(D, -0.5)\n",
    "    L = inv_sqrt_D.reshape(-1, 1) * A * inv_sqrt_D.reshape(1, -1)\n",
    "    return L\n",
    "\n",
    "\n",
    "# Function to generate RTTM entries\n",
    "def generate_rttm(\n",
    "    speech_segments, frame_predictions, block_size, sampling_rate, output_file\n",
    "):\n",
    "    rttm_lines = []\n",
    "    segment_index = 0\n",
    "    frame_index = 0\n",
    "\n",
    "    # Loop over the speech segments\n",
    "    for segment in speech_segments:\n",
    "        start_time = segment[\"start\"]\n",
    "        end_time = segment[\"end\"]\n",
    "        segment_duration = end_time - start_time\n",
    "\n",
    "        # Calculate number of frames that fit into this segment\n",
    "        num_frames_in_segment = int(\n",
    "            np.ceil(segment_duration * sampling_rate / block_size)\n",
    "        )\n",
    "\n",
    "        for _ in range(num_frames_in_segment):\n",
    "            if frame_index >= len(frame_predictions):\n",
    "                break\n",
    "\n",
    "            frame_start_time = start_time + (frame_index * block_size / sampling_rate)\n",
    "            frame_end_time = frame_start_time + (block_size / sampling_rate)\n",
    "\n",
    "            if frame_end_time > end_time:\n",
    "                frame_end_time = end_time\n",
    "\n",
    "            duration = frame_end_time - frame_start_time\n",
    "            cluster_id = frame_predictions[frame_index]\n",
    "\n",
    "            rttm_line = f\"SPEAKER unknown 1 {frame_start_time:.3f} {duration:.3f} <NA> <NA> speaker_{cluster_id} <NA> <NA>\"\n",
    "            rttm_lines.append(rttm_line)\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for line in rttm_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "    print(f\"RTTM file generated at: {output_file}\")\n",
    "\n",
    "# Iterate over all files at the test path\n",
    "for file in os.listdir(TEST_PATH):\n",
    "    print(f\"Processing file: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/232 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "sox extension is not supported on Windows",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m speech_segments_time \u001b[38;5;241m=\u001b[39m convert_samples_to_time(speech_segments, wave_sampling_rate)\n\u001b[0;32m      9\u001b[0m wave_tensor_torch, wave_sampling_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path)\n\u001b[1;32m---> 10\u001b[0m wave_tensor, mel_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mwave2mel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwave_tensor_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwave_sampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get the features\u001b[39;00m\n\u001b[0;32m     13\u001b[0m mel_frames \u001b[38;5;241m=\u001b[39m get_frames(mel_tensor, BLOCK_SIZE)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\preprocess.py:44\u001b[0m, in \u001b[0;36mWav2Mel.forward\u001b[1;34m(self, wav_tensor, sample_rate)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, wav_tensor: torch\u001b[38;5;241m.\u001b[39mTensor, sample_rate: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 44\u001b[0m     wav_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msox_effects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     mel_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_melspectrogram(wav_tensor)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_tensor, mel_tensor\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\preprocess.py:76\u001b[0m, in \u001b[0;36mSoxEffects.forward\u001b[1;34m(self, wav_tensor, sample_rate)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, wav_tensor: torch\u001b[38;5;241m.\u001b[39mTensor, sample_rate: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 76\u001b[0m     wav_tensor, _ \u001b[38;5;241m=\u001b[39m \u001b[43mapply_effects_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wav_tensor\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torchaudio\\sox_effects\\sox_effects.py:156\u001b[0m, in \u001b[0;36mapply_effects_tensor\u001b[1;34m(tensor, sample_rate, effects, channels_first)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_effects_tensor\u001b[39m(\n\u001b[0;32m     56\u001b[0m     tensor: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m     57\u001b[0m     sample_rate: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m     58\u001b[0m     effects: List[List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m     59\u001b[0m     channels_first: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     60\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply sox effects to given Tensor\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    .. devices:: CPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m        >>> assert sample_rate == 8000\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msox_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_effects_tensor\u001b[49m(tensor, sample_rate, effects, channels_first)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torchaudio\\_extension\\utils.py:121\u001b[0m, in \u001b[0;36m_LazyImporter.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_import_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, item)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torchaudio\\_extension\\utils.py:135\u001b[0m, in \u001b[0;36m_LazyImporter._import_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_import_once\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;66;03m# By attaching the module attributes to self,\u001b[39;00m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;66;03m# module attributes are directly accessible.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;66;03m# This allows to avoid calling __getattr__ for every attribute access.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torchaudio\\_extension\\utils.py:85\u001b[0m, in \u001b[0;36m_init_sox\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_sox\u001b[39m():\n\u001b[1;32m---> 85\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43m_import_sox_ext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     ext\u001b[38;5;241m.\u001b[39mset_verbosity(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01matexit\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\torchaudio\\_extension\\utils.py:66\u001b[0m, in \u001b[0;36m_import_sox_ext\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_import_sox_ext\u001b[39m():\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msox extension is not supported on Windows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m eval_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHAUDIO_USE_SOX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msox extension is disabled. (TORCHAUDIO_USE_SOX=0)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: sox extension is not supported on Windows"
     ]
    }
   ],
   "source": [
    "# Running it on all the files in the test folder\n",
    "for file in tqdm(os.listdir(TEST_PATH)):\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Skip non-audio files\n",
    "    if not file.endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    # If the file is empty, skip it\n",
    "    if os.path.getsize(os.path.join(TEST_PATH, file)) == 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # Get audio, preprocess it, get segment and move it all to CUDA\n",
    "    audio_path = os.path.join(TEST_PATH, file)\n",
    "    wave_tensor_torch, wave_sampling_rate = torchaudio.load(audio_path)\n",
    "    wave_tensor_torch = wave_tensor_torch.to(device)\n",
    "    speech_segments = get_speech_timestamps(wave_tensor_torch, model=vad_model)\n",
    "    speech_segments_time = convert_samples_to_time(speech_segments, wave_sampling_rate)\n",
    "    wave_tensor_torch, wave_sampling_rate = torchaudio.load(audio_path)\n",
    "    wave_tensor, mel_tensor = wave2mel(wave_tensor_torch, wave_sampling_rate)\n",
    "\n",
    "    # Get the features\n",
    "    mel_frames = get_frames(mel_tensor, BLOCK_SIZE)\n",
    "    embeddings = get_frame_embeddings(mel_frames)\n",
    "\n",
    "    # Spectral clustering part\n",
    "    distance = pdist(embeddings, metric=\"euclidean\")\n",
    "\n",
    "    A = 1 / (1 + distance)\n",
    "    A = squareform(A)\n",
    "    A = A - np.diag(np.diag(A))  # set diagonal to zero\n",
    "    L = normalized_laplacian_matrix(A)\n",
    "    w, v = np.linalg.eig(L)\n",
    "    eigenvalues = np.real(w)\n",
    "    num_vectors = np.argmin(np.diff(eigenvalues)) + 1\n",
    "    num_vectors = 3\n",
    "    eigenvectors = np.real(v[:, 0:num_vectors])\n",
    "\n",
    "    norm_eigenvectors = eigenvectors / np.linalg.norm(\n",
    "        eigenvectors, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    frame_predictions = KMeans(\n",
    "        n_clusters=norm_eigenvectors.shape[1], n_init=5\n",
    "    ).fit_predict(norm_eigenvectors)\n",
    "\n",
    "    output_file = os.path.join(OUTPUT_PATH, f\"{file}.rttm\")\n",
    "\n",
    "    # Generate RTTM entries\n",
    "    generate_rttm(\n",
    "        speech_segments_time,\n",
    "        frame_predictions,\n",
    "        BLOCK_SIZE,\n",
    "        wave_sampling_rate,\n",
    "        output_file,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
