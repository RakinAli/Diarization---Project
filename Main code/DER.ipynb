{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DER calculation\n",
    "This file is used to calculate Diarization Error Rate. It is calculated as follows:\n",
    "1. For each speaker, we calculate the number of false alarms, missed detections and overlapped speech.\n",
    "2. We sum up the number of false alarms, missed detections and overlapped speech.\n",
    "3. We divide the sum by the total number of speaker speech segments.\n",
    "4. The result is the DER.\n",
    "\n",
    "The formula is as follows:\n",
    "$$\n",
    "DER = \\frac{FA + MISS + OVER}{N_{spk}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $FA$ is the number of false alarms\n",
    "- $MISS$ is the number of missed detections\n",
    "- $OVER$ is the number of overlapped speech\n",
    "- $N_{spk}$ is the total number of speaker speech segments\n",
    "\n",
    "The code below is used to calculate the DER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/232 [00:00<00:09, 23.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missed detection': 0.0, 'confusion': 32.65, 'false alarm': 59.300000000000004, 'correct': 2430.3499999999995, 'total': 2463.0, 'diarization error rate': 0.03733252131546894}\n",
      "{'missed detection': 0.040000000000020464, 'confusion': 790.1100000000001, 'false alarm': 303.5400000000001, 'correct': 3838.48, 'total': 4628.629999999999, 'diarization error rate': 0.23628805931776795}\n",
      "{'missed detection': 0.0, 'confusion': 15.319999999999993, 'false alarm': 817.0699999999998, 'correct': 3930.1600000000003, 'total': 3945.48, 'diarization error rate': 0.2109730628465991}\n",
      "{'missed detection': 0.0, 'confusion': 14402.389999999996, 'false alarm': 12819.560000000003, 'correct': 36996.07000000002, 'total': 51398.45999999999, 'diarization error rate': 0.5296257903446913}\n",
      "{'missed detection': 863.6400000000001, 'confusion': 769.55, 'false alarm': 0.11000000000001364, 'correct': 6591.9400000000005, 'total': 8225.13, 'diarization error rate': 0.19857436903732834}\n",
      "{'missed detection': 1441.7600000000004, 'confusion': 0.0, 'false alarm': 0.0, 'correct': 102939.99999999996, 'total': 104381.76, 'diarization error rate': 0.01381237488235493}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/232 [00:03<01:55,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missed detection': 832.28, 'confusion': 19332.67999999999, 'false alarm': 6709.069999999997, 'correct': 119470.10000000003, 'total': 139635.0599999999, 'diarization error rate': 0.19245904287934565}\n",
      "{'missed detection': 2900.4700000000003, 'confusion': 228.2799999999999, 'false alarm': 0.0, 'correct': 12714.040000000005, 'total': 15842.790000000014, 'diarization error rate': 0.19748731126272565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/232 [00:04<02:02,  1.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m prediction \u001b[38;5;241m=\u001b[39m load_rttm(path_oracle_vad)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate DER and components manually\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m detailed \u001b[38;5;241m=\u001b[39m der_metric(ground_truth, prediction, detailed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(detailed)\n\u001b[0;32m     50\u001b[0m der \u001b[38;5;241m=\u001b[39m detailed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiarization error rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\metrics\\base.py:114\u001b[0m, in \u001b[0;36mBaseMetric.__call__\u001b[1;34m(self, reference, hypothesis, detailed, uri, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute metric value and accumulate components\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    `components` updated with metric value\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# compute metric components\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_components(reference, hypothesis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# compute rate based on components\u001b[39;00m\n\u001b[0;32m    117\u001b[0m components[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_name_] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metric(components)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\metrics\\diarization.py:167\u001b[0m, in \u001b[0;36mDiarizationErrorRate.compute_components\u001b[1;34m(self, reference, hypothesis, uem, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# compute identification error rate based on mapped hypothesis\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# NOTE that collar is set to 0.0 because 'uemify' has already\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# been applied (same reason for setting skip_overlap to False)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m mapped \u001b[38;5;241m=\u001b[39m hypothesis\u001b[38;5;241m.\u001b[39mrename_labels(mapping\u001b[38;5;241m=\u001b[39mmapping)\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(DiarizationErrorRate, \u001b[38;5;28mself\u001b[39m) \\\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;241m.\u001b[39mcompute_components(reference, mapped, uem\u001b[38;5;241m=\u001b[39muem,\n\u001b[0;32m    169\u001b[0m                         collar\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, skip_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\metrics\\identification.py:133\u001b[0m, in \u001b[0;36mIdentificationErrorRate.compute_components\u001b[1;34m(self, reference, hypothesis, uem, collar, skip_overlap, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_overlap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     skip_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_overlap\n\u001b[1;32m--> 133\u001b[0m R, H, common_timeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muemify(\n\u001b[0;32m    134\u001b[0m     reference, hypothesis, uem\u001b[38;5;241m=\u001b[39muem,\n\u001b[0;32m    135\u001b[0m     collar\u001b[38;5;241m=\u001b[39mcollar, skip_overlap\u001b[38;5;241m=\u001b[39mskip_overlap,\n\u001b[0;32m    136\u001b[0m     returns_timeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# loop on all segments\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m common_timeline:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# segment duration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\metrics\\utils.py:215\u001b[0m, in \u001b[0;36mUEMSupportMixin.uemify\u001b[1;34m(self, reference, hypothesis, uem, collar, skip_overlap, returns_uem, returns_timeline)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returns_timeline:\n\u001b[0;32m    214\u001b[0m     timeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommon_timeline(reference, hypothesis)\n\u001b[1;32m--> 215\u001b[0m     reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(reference, timeline)\n\u001b[0;32m    216\u001b[0m     hypothesis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(hypothesis, timeline)\n\u001b[0;32m    218\u001b[0m result \u001b[38;5;241m=\u001b[39m (reference, hypothesis)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\metrics\\utils.py:143\u001b[0m, in \u001b[0;36mUEMSupportMixin.project\u001b[1;34m(self, annotation, timeline)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment_, segment \u001b[38;5;129;01min\u001b[39;00m timeline_\u001b[38;5;241m.\u001b[39mco_iter(timeline):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m track_ \u001b[38;5;129;01min\u001b[39;00m annotation\u001b[38;5;241m.\u001b[39mget_tracks(segment_):\n\u001b[1;32m--> 143\u001b[0m         track \u001b[38;5;241m=\u001b[39m projection\u001b[38;5;241m.\u001b[39mnew_track(segment, candidate\u001b[38;5;241m=\u001b[39mtrack_)\n\u001b[0;32m    144\u001b[0m         projection[segment, track] \u001b[38;5;241m=\u001b[39m annotation[segment_, track_]\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m projection\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pyannote\\core\\annotation.py:768\u001b[0m, in \u001b[0;36mAnnotation.new_track\u001b[1;34m(self, segment, candidate, prefix)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# find first non-existing track name for segment\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# eg. if '0' exists, try '1', then '2', ...\u001b[39;00m\n\u001b[0;32m    767\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 768\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (prefix, count)) \u001b[38;5;129;01min\u001b[39;00m existing_tracks:\n\u001b[0;32m    769\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# return first non-existing track name\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyannote.core import Annotation, Segment\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# Paths to the different RTTM files\n",
    "RTTM_TRUTH = \"../Dataset/RTTMs/Test\"\n",
    "RTTM_ORACLE_VAD = \"../Results/Oracle_vad/Test\"\n",
    "RTTM_ORACLE_DECODER = \"../Results/Oracle_decoder/Test\"\n",
    "\n",
    "\n",
    "# Load the RTTM files\n",
    "def load_rttm(filename):\n",
    "    \"\"\"Load RTTM file and convert it to pyannote.core.Annotation\"\"\"\n",
    "    annotation = Annotation()\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            file_id, channel, start_time, duration, _, _, *speaker_parts = parts\n",
    "            speaker = \" \".join(speaker_parts)\n",
    "            start_time = float(start_time)\n",
    "            duration = float(duration)\n",
    "            end_time = start_time + duration\n",
    "            segment = Segment(start_time, end_time)\n",
    "            annotation[segment] = speaker\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def calculate_der_metrics(ground_truth_path, prediction_path, output_csv):\n",
    "    \"\"\"\n",
    "    This function calculates DER metrics for diarization and saves them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        ground_truth_path: Path to the directory containing ground truth RTTM files.\n",
    "        prediction_path: Path to the directory containing prediction RTTM files.\n",
    "        output_csv: The name (including path) for the CSV file to store results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the diarization error rate metric\n",
    "    der_metric = DiarizationErrorRate()\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over files in prediction directory\n",
    "    for file_name in tqdm(os.listdir(prediction_path)):\n",
    "        truth_file = os.path.join(ground_truth_path, file_name)\n",
    "        prediction_file = os.path.join(prediction_path, file_name)\n",
    "\n",
    "        if os.path.exists(truth_file) and os.path.exists(prediction_file):\n",
    "            ground_truth = load_rttm(truth_file)\n",
    "            prediction = load_rttm(prediction_file)\n",
    "\n",
    "            # Calculate DER and components manually\n",
    "            detailed = der_metric(ground_truth, prediction, detailed=True)\n",
    "            print(detailed)\n",
    "\n",
    "            der = detailed[\"diarization error rate\"]\n",
    "\n",
    "            # Assuming \"confusion\" represents combined missed speech and speaker error\n",
    "            confusion_duration = detailed[\"confusion\"]\n",
    "\n",
    "            # Calculate False Alarm (FA) duration\n",
    "            false_alarm = detailed[\"false alarm\"]\n",
    "\n",
    "            # Missed Speech (OVER) can be approximated by subtracting FA from confusion\n",
    "            missed_speech = confusion_duration - false_alarm\n",
    "\n",
    "            total_duration = detailed[\"total\"]\n",
    "\n",
    "            # Append results\n",
    "            results.append(\n",
    "                {\n",
    "                    \"File\": file_name,\n",
    "                    \"DER\": der,\n",
    "                    \"Miss Duration\": missed_speech / total_duration,\n",
    "                    \"Speaker Error Duration\": confusion_duration / total_duration\n",
    "                    - missed_speech / total_duration,\n",
    "                    \"False Alarm Duration\": false_alarm / total_duration,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"File {file_name} not found\")\n",
    "            sys.exit(1)  # Exit with an error if a file is missing\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
