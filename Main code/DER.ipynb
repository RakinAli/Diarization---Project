{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DER calculation\n",
    "This file is used to calculate Diarization Error Rate. It is calculated as follows:\n",
    "1. For each speaker, we calculate the number of false alarms, missed detections and overlapped speech.\n",
    "2. We sum up the number of false alarms, missed detections and overlapped speech.\n",
    "3. We divide the sum by the total number of speaker speech segments.\n",
    "4. The result is the DER.\n",
    "\n",
    "The formula is as follows:\n",
    "$$\n",
    "DER = \\frac{FA + MISS + OVER}{N_{spk}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $FA$ is the number of false alarms\n",
    "- $MISS$ is the number of missed detections\n",
    "- $OVER$ is the number of overlapped speech\n",
    "- $N_{spk}$ is the total number of speaker speech segments\n",
    "\n",
    "The code below is used to calculate the DER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyannote.core import Annotation, Segment\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyannote.core import Annotation, Segment\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"'uem' was approximated by the union of 'reference' and 'hypothesis' extents\",\n",
    ")\n",
    "\n",
    "\n",
    "\"../Results/Diarization_pipeline\"\n",
    "# Paths to the different RTTM files\n",
    "RTTM_TRUTH = \"../Dataset/RTTMs/Test\"\n",
    "\n",
    "# Prebuilt diarization pipeline\n",
    "RTTM_ORACLE_VAD = \"../Results/Nemo without MSD/Test\"\n",
    "RTTM_ORACLE_DECODER = \"../Results/Nemo with MSDD/Test\"\n",
    "RTTM_PYANNOTE = \"../Results/Pyannote/Test\"\n",
    "\n",
    "# Custom pipeline diarization results --> All of them ran on test directly\n",
    "RTTM_ESCAPA_AHC = \"../Results/Custom pipeline/ecapa_ahc\"\n",
    "RTTM_ESCAPA_SC = \"../Results/Custom pipeline/ecapa_sc\"\n",
    "RTTM_XVECTOR_AHC = \"../Results/Custom pipeline/xvec_ahc\"\n",
    "RTTM_XVECTOR_SC = \"../Results/Custom pipeline/xvec_sc\"\n",
    "\n",
    "\n",
    "RESULTS_DIRECTORY = \"../Results/DER Results\"\n",
    "IMAGE_DIRECTORY = \"../Images/RTTM_vis/\"\n",
    "\n",
    "\n",
    "def rttm_to_annotation(rttm_file):\n",
    "    annotation = Annotation()\n",
    "\n",
    "    with open(rttm_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 10:\n",
    "                continue\n",
    "\n",
    "            speaker = parts[7]\n",
    "            start_time = float(parts[3])\n",
    "            duration = float(parts[4])\n",
    "            end_time = start_time + duration\n",
    "\n",
    "            annotation[Segment(start_time, end_time)] = speaker\n",
    "\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def plot_annotations(ground_truth, predicted, output_file, title=\"Annotation Plot\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    # Plot predicted labels\n",
    "    for segment, track, label in predicted.itertracks(yield_label=True):\n",
    "        ax1.plot([segment.start, segment.end], [label, label], lw=6)\n",
    "    ax1.set_ylabel(\"Predicted\")\n",
    "    ax1.set_yticks(list(set(predicted.labels())))\n",
    "    ax1.set_yticklabels(list(set(predicted.labels())))\n",
    "    ax1.set_title(f\"{title} - Predicted\")\n",
    "\n",
    "    # Plot ground truth labels\n",
    "    for segment, track, label in ground_truth.itertracks(yield_label=True):\n",
    "        ax2.plot([segment.start, segment.end], [label, label], lw=6)\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.set_ylabel(\"Ground Truth\")\n",
    "    ax2.set_yticks(list(set(ground_truth.labels())))\n",
    "    ax2.set_yticklabels(list(set(ground_truth.labels())))\n",
    "    ax2.set_title(f\"{title} - Ground Truth\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_file = os.path.join(output_file, title + \".png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Load the RTTM files\n",
    "def load_rttm(filename):\n",
    "    \"\"\"Load RTTM file and convert it to pyannote.core.Annotation\"\"\"\n",
    "    annotation = Annotation()\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            file_id, channel, start_time, duration, _, _, *speaker_parts = parts\n",
    "            speaker = \" \".join(speaker_parts)\n",
    "            start_time = float(start_time)\n",
    "            duration = float(duration)\n",
    "            end_time = start_time + duration\n",
    "            segment = Segment(start_time, end_time)\n",
    "            annotation[segment] = speaker\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def calculate_der_metrics(\n",
    "    ground_truth_path, prediction_path, image_directory, output_csv=\"der_results.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    This function calculates DER metrics for diarization and saves them to a CSV file,\n",
    "    including a row with average metrics.\n",
    "\n",
    "    Args:\n",
    "        ground_truth_path: Path to the directory containing ground truth RTTM files.\n",
    "        prediction_path: Path to the directory containing prediction RTTM files.\n",
    "        image_directory: Directory to save the output images.\n",
    "        output_csv: Path (including filename) for the output CSV file. Defaults to \"der_results.csv\" if not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the diarization error rate metric\n",
    "    der_metric = DiarizationErrorRate(skip_overlap=True)\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "    total_der = 0\n",
    "    total_miss_duration = 0\n",
    "    total_speaker_error_duration = 0\n",
    "    total_false_alarm_duration = 0\n",
    "    total_duration = 0\n",
    "\n",
    "    # Iterate over files in prediction directory\n",
    "    for file_name in tqdm(os.listdir(prediction_path)):\n",
    "        truth_file = os.path.join(ground_truth_path, file_name)\n",
    "        prediction_file = os.path.join(prediction_path, file_name)\n",
    "\n",
    "        if os.path.exists(truth_file) and os.path.exists(prediction_file):\n",
    "            ground_truth = rttm_to_annotation(truth_file)\n",
    "            prediction = rttm_to_annotation(prediction_file)\n",
    "\n",
    "            # Calculate DER and components manually\n",
    "            detailed = der_metric(ground_truth, prediction, detailed=True)\n",
    "            der = detailed[\"diarization error rate\"]\n",
    "\n",
    "            # if DER is greater than 1, there is an error in the file. Skip the file.\n",
    "            if der > 1:\n",
    "                print(f\"DER for {file_name} is greater than 1. Check the files.\")\n",
    "                continue\n",
    "\n",
    "            confusion_duration = detailed[\"confusion\"]\n",
    "            false_alarm = detailed[\"false alarm\"]\n",
    "            missed_speech = detailed[\"missed detection\"]\n",
    "            total_file_duration = detailed[\"total\"]\n",
    "\n",
    "            # Accumulate totals for average calculation\n",
    "            total_der += der\n",
    "            total_miss_duration += missed_speech\n",
    "            total_speaker_error_duration += confusion_duration\n",
    "            total_false_alarm_duration += false_alarm\n",
    "            total_duration += total_file_duration\n",
    "\n",
    "            # Append results for this file\n",
    "            results.append(\n",
    "                {\n",
    "                    \"File\": file_name,\n",
    "                    \"DER\": der,\n",
    "                    \"Miss Duration\": missed_speech / total_file_duration,\n",
    "                    \"Speaker Error Duration\": confusion_duration / total_file_duration,\n",
    "                    \"False Alarm Duration\": false_alarm / total_file_duration,\n",
    "                }\n",
    "            )\n",
    "            # Plot the ground truth and prediction\n",
    "            plot_annotations(ground_truth, prediction, IMAGE_DIRECTORY, title=file_name)\n",
    "        else:\n",
    "            print(f\"File {file_name} not found\")\n",
    "            print(\"Looked at path: \", prediction_file)\n",
    "            sys.exit(1)  # Exit with an error if a file is missing\n",
    "\n",
    "    # Calculate average metrics (assuming all files have processed)\n",
    "    if total_duration > 0:  # Avoid division by zero\n",
    "        average_der = total_der / len(results)\n",
    "        average_miss_duration = total_miss_duration / total_duration\n",
    "        average_speaker_error_duration = total_speaker_error_duration / total_duration\n",
    "        average_false_alarm_duration = total_false_alarm_duration / total_duration\n",
    "\n",
    "        # Create a dictionary for average metrics\n",
    "        average_metrics = {\n",
    "            \"File\": \"Average\",\n",
    "            \"DER\": average_der,\n",
    "            \"Miss Duration\": average_miss_duration,\n",
    "            \"Speaker Error Duration\": average_speaker_error_duration,\n",
    "            \"False Alarm Duration\": average_false_alarm_duration,\n",
    "        }\n",
    "\n",
    "        # Append average metrics to results\n",
    "        results.append(average_metrics)\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 194/232 [00:53<00:11,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER for vylyk.rttm is greater than 1. Check the files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [01:03<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate DER metrics for Oracle VAD\n",
    "\n",
    "# calculate_der_metrics(RTTM_TRUTH, RTTM_PYANNOTE, RESULTS_DIRECTORY, \"Pyannote.csv\")\n",
    "\n",
    "# calculate_der_metrics(RTTM_TRUTH, RTTM_ORACLE_VAD, os.path.join(RESULTS_DIRECTORY, \"der_oracle_vad.csv\"),\"Nemo_without_MSD.csv\")\n",
    "\n",
    "\n",
    "# Calculate DER metrics for Oracle Decoder\n",
    "# calculate_der_metrics(RTTM_TRUTH, RTTM_ORACLE_DECODER, os.path.join(RESULTS_DIRECTORY, \"der_oracle_decoder.csv\"), \"Nemo_with_MSD.csv\")\n",
    "\n",
    "\n",
    "# Calculate DER metrics FOR ESCAPA SC\n",
    "# calculate_der_metrics(RTTM_TRUTH, RTTM_ESCAPA_SC, os.path.join(RESULTS_DIRECTORY, \"der_escapa_sc.csv\"), \"ecapa_sc.csv\")\n",
    "\n",
    "# Calculate DER metrics FOR ESCAPA AHC\n",
    "#calculate_der_metrics(RTTM_TRUTH, RTTM_ESCAPA_AHC, os.path.join(RESULTS_DIRECTORY, \"der_escapa_ahc.csv\"), \"ecapa_ahc.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate DER metrics FOR XVECTOR SC\n",
    "#calculate_der_metrics(RTTM_TRUTH, RTTM_XVECTOR_SC, os.path.join(RESULTS_DIRECTORY, \"der_xvector_sc.csv\"))\n",
    "\n",
    "\n",
    "# Calculate DER metrics FOR XVECTOR AHC\n",
    "calculate_der_metrics(RTTM_TRUTH, RTTM_XVECTOR_AHC, os.path.join(RESULTS_DIRECTORY, \"der_xvector_ahc.csv\"),\"x_vector_ahc.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
