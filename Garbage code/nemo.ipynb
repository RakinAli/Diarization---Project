{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from nemo.collections.asr.parts.utils.speaker_utils import (\n",
    "    rttm_to_labels,\n",
    "    labels_to_pyannote_object,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "data_directory = \"../Dataset/Audio/Dev\"\n",
    "rttm_directory = \"../Dataset/RTTMs/Dev\"\n",
    "\n",
    "# Specify the file names\n",
    "an4_audio = os.path.join(data_directory, \"afjiv.wav\")\n",
    "an4_rttm = os.path.join(rttm_directory, \"afjiv.rttm\")\n",
    "\n",
    "# Ensure the files exist\n",
    "if not os.path.exists(an4_audio):\n",
    "    raise FileNotFoundError(f\"{an4_audio} not found.\")\n",
    "if not os.path.exists(an4_rttm):\n",
    "    raise FileNotFoundError(f\"{an4_rttm} not found.\")\n",
    "\n",
    "# Load and plot the audio\n",
    "sr = 16000\n",
    "signal, sr = librosa.load(an4_audio, sr=sr)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(2)\n",
    "plt.plot(np.arange(len(signal)), signal, \"gray\")\n",
    "fig.suptitle(\"Reference merged an4 audio\", fontsize=16)\n",
    "plt.xlabel(\"time (secs)\", fontsize=18)\n",
    "ax.margins(x=0)\n",
    "plt.ylabel(\"signal strength\", fontsize=16)\n",
    "a, _ = plt.xticks()\n",
    "plt.xticks(a, a / sr)\n",
    "\n",
    "# Play the audio\n",
    "IPython.display.Audio(an4_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.parts.utils.speaker_utils import (\n",
    "    rttm_to_labels,\n",
    "    labels_to_pyannote_object,\n",
    ")\n",
    "labels = rttm_to_labels(an4_rttm)\n",
    "reference = labels_to_pyannote_object(labels)\n",
    "print(labels)\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a manifest for input with below format.\n",
    "# {'audio_filepath': /path/to/audio_file, 'offset': 0, 'duration':None, 'label': 'infer', 'text': '-',\n",
    "# 'num_speakers': None, 'rttm_filepath': /path/to/rttm/file, 'uem_filepath'='/path/to/uem/filepath'}\n",
    "import json\n",
    "\n",
    "# Define the root and data directory\n",
    "ROOT = os.getcwd()\n",
    "data_dir = os.path.join(ROOT, 'data')\n",
    "\n",
    "# Ensure the data directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Create the metadata dictionary\n",
    "meta = {\n",
    "    \"audio_filepath\": an4_audio,\n",
    "    \"offset\": 0,\n",
    "    \"duration\": None,\n",
    "    \"label\": \"infer\",\n",
    "    \"text\": \"-\",\n",
    "    \"num_speakers\": None,\n",
    "    \"rttm_filepath\": an4_rttm,\n",
    "    \"uem_filepath\": None,\n",
    "}\n",
    "\n",
    "# Write the metadata to a JSON file\n",
    "manifest_path = os.path.join(data_dir, \"input_manifest.json\")\n",
    "with open(manifest_path, \"w\") as fp:\n",
    "    json.dump(meta, fp)\n",
    "    fp.write(\"\\n\")\n",
    "\n",
    "# Display the content of the JSON file\n",
    "with open(manifest_path, \"r\") as fp:\n",
    "    content = fp.read()\n",
    "    print(content)\n",
    "\n",
    "# Create the output directory\n",
    "output_dir = os.path.join(ROOT, \"oracle_vad\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import wget\n",
    "\n",
    "MODEL_CONFIG = os.path.join(data_dir, \"diar_infer_telephonic.yaml\")\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_telephonic.yaml\"\n",
    "    MODEL_CONFIG = wget.download(config_url, data_dir)\n",
    "\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.diarizer.manifest_filepath = \"data/input_manifest.json\"\n",
    "config.diarizer.out_dir = (\n",
    "    output_dir  # Directory to store intermediate files and prediction outputs\n",
    ")\n",
    "pretrained_speaker_model = \"titanet_large\"\n",
    "config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [\n",
    "    1.5,\n",
    "    1.25,\n",
    "    1.0,\n",
    "    0.75,\n",
    "    0.5,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [\n",
    "    0.75,\n",
    "    0.625,\n",
    "    0.5,\n",
    "    0.375,\n",
    "    0.1,\n",
    "]\n",
    "config.diarizer.speaker_embeddings.parameters.multiscale_weights = [1, 1, 1, 1, 1]\n",
    "config.diarizer.oracle_vad = True  # ----> ORACLE VAD\n",
    "config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "print(\"Config: \\n\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import ClusteringDiarizer\n",
    "oracle_vad_clusdiar_model = ClusteringDiarizer(cfg=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-29 20:13:24 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:24 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-05-29 20:13:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\subsegments_scale0.json\n",
      "[NeMo I 2024-05-29 20:13:24 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-29 20:13:24 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-29 20:13:24 collections:733] Dataset loaded with 154 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-29 20:13:24 collections:735] # 154 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:24 clustering_diarizer:389] Saved embedding files to c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-29 20:13:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\subsegments_scale1.json\n",
      "[NeMo I 2024-05-29 20:13:24 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-29 20:13:24 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-29 20:13:24 collections:733] Dataset loaded with 184 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-29 20:13:24 collections:735] # 184 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 30.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:389] Saved embedding files to c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\subsegments_scale2.json\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-29 20:13:25 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-29 20:13:25 collections:733] Dataset loaded with 233 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-29 20:13:25 collections:735] # 233 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00, 32.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:389] Saved embedding files to c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\subsegments_scale3.json\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-29 20:13:25 collections:732] Filtered duration for loading collection is  0.00 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 collections:733] Dataset loaded with 318 items, total duration of  0.06 hours.\n",
      "[NeMo I 2024-05-29 20:13:25 collections:735] # 318 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:389] Saved embedding files to c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\embeddings\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\subsegments_scale4.json\n",
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:343] Extracting embeddings for Diarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 collections:732] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-29 20:13:25 collections:733] Dataset loaded with 1136 items, total duration of  0.16 hours.\n",
      "[NeMo I 2024-05-29 20:13:25 collections:735] # 1136 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5/5] extract embeddings: 100%|██████████| 18/18 [00:00<00:00, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:25 clustering_diarizer:389] Saved embedding files to c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad\\speaker_outputs\\embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:26 clustering_diarizer:464] Outputs are saved in c:\\Users\\rakin\\Documents\\GitHub\\Speaker-Diarization\\Main code\\oracle_vad directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2024-05-29 20:13:26 nemo_logging:349] c:\\Users\\rakin\\anaconda3\\envs\\nemo\\lib\\site-packages\\pyannote\\metrics\\utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-29 20:13:26 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap True: \n",
      "     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0000\t, Confusion ER:0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pyannote.metrics.diarization.DiarizationErrorRate at 0x1a812e945e0>,\n",
       " {'afjiv': {'speaker_0': 'spk02',\n",
       "   'speaker_1': 'spk00',\n",
       "   'speaker_2': 'spk03',\n",
       "   'speaker_3': 'spk01',\n",
       "   'speaker_4': 'spk04'}},\n",
       " (0.0, 0.0, 0.0, 0.0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And lets diarize\n",
    "oracle_vad_clusdiar_model.diarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Diarizer Result (RTTM format)\n",
      "['5.28 34.519999999999996 speaker_2', '34.68 40.08 speaker_2', '40.12 40.96 speaker_2', '41.12 80.47999999999999 speaker_1', '80.92 83.72 speaker_0', '84.84 86.08 speaker_0', '87.08 88.0 speaker_0', '88.72 93.03999999999999 speaker_0', '93.08 94.36 speaker_0', '95.12 98.0 speaker_4', '98.72 100.44 speaker_4', '101.12 104.60000000000001 speaker_4', '105.56 107.08 speaker_4', '107.16 107.6 speaker_4', '108.16 110.03999999999999 speaker_4', '111.0 113.28 speaker_4', '113.84 118.12 speaker_4', '119.44 122.32 speaker_3', '122.96 124.55999999999999 speaker_3', '125.2 128.4 speaker_3', '128.48 129.64 speaker_3', '130.88 133.51999999999998 speaker_3', '133.68 134.12 speaker_3', '135.72 138.16 speaker_3', '138.92 140.48 speaker_3', '140.64 141.64 speaker_3', '142.2 144.32 speaker_3', '144.6 145.32 speaker_3']\n",
      "Ground-truth Speaker Labels\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering Diarizer Result (RTTM format)\")\n",
    "pred_labels_neural = rttm_to_labels(f\"{output_dir}/pred_rttms/afjiv.rttm\")\n",
    "hypothesis_neural = labels_to_pyannote_object(pred_labels_neural)\n",
    "print(pred_labels_neural)\n",
    "print(\"Ground-truth Speaker Labels\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
