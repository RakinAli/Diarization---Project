{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "In this part of the notebook, we will preprocess the data to make it ready for training. We will do the following steps:\n",
    "1. Visualize the RTM data\n",
    "2. Check the sampling rate of the data and resample to consist to 16kHz to enssure uniformity across the dataset\n",
    "3. Extract MFCC features from the audio data and allign with the RTM data to create the final dataset\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the RTM data\n",
    "\n",
    "# All imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as librosa\n",
    "import sys\n",
    "import tqdm as tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Parse the dummy RTTM file\n",
    "def parse_rttm(file_path):\n",
    "    columns = [\n",
    "        \"Type\",\n",
    "        \"File ID\",\n",
    "        \"Channel ID\",\n",
    "        \"Turn Onset\",\n",
    "        \"Turn Duration\",\n",
    "        \"Orthography Field\",\n",
    "        \"Speaker Type\",\n",
    "        \"Speaker Name\",\n",
    "        \"Confidence Score\",\n",
    "        \"Signal Lookahead Time\",\n",
    "    ]\n",
    "    df = pd.read_csv(file_path, sep=\"\\s+\", names=columns)\n",
    "    return df[[\"Turn Onset\", \"Turn Duration\", \"Speaker Name\"]]\n",
    "\n",
    "\n",
    "# Grabs the important data from the RTM file and creats End Time column\n",
    "def prepare_data(rttm_data):\n",
    "    rttm_data[\"Turn Onset\"] = rttm_data[\"Turn Onset\"].astype(float)\n",
    "    rttm_data[\"Turn Duration\"] = rttm_data[\"Turn Duration\"].astype(float)\n",
    "    rttm_data[\"End Time\"] = rttm_data[\"Turn Onset\"] + rttm_data[\"Turn Duration\"]\n",
    "    return rttm_data\n",
    "\n",
    "\n",
    "# Plots the timeline of the speakers\n",
    "def plot_timeline(data):\n",
    "    \"\"\"\n",
    "    Plots the speaker timeline based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data containing speaker information.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    speakers = data[\"Speaker Name\"].unique()\n",
    "    speaker_indices = {speaker: idx for idx, speaker in enumerate(speakers)}\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        start = row[\"Turn Onset\"]\n",
    "        end = row[\"End Time\"]\n",
    "        speaker = row[\"Speaker Name\"]\n",
    "        ax.plot([start, end], [speaker_indices[speaker]] * 2, linewidth=10)\n",
    "\n",
    "    ax.set_yticks(range(len(speakers)))\n",
    "    ax.set_yticklabels(speakers)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Speakers\")\n",
    "    ax.set_title(\"Speaker Timeline\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def debugger_test():\n",
    "    # Test the RTM data\n",
    "    rttm_data = parse_rttm(\"../Dataset/RTMS/Dev/abjxc.rttm\")\n",
    "    rttm_data = prepare_data(rttm_data)\n",
    "    plot_timeline(rttm_data)\n",
    "\n",
    "\n",
    "def debugger_run_all():\n",
    "    devRTM_path = \"../Dataset/RTMS/Dev/\"\n",
    "    # Visaualize all RTM data in the folder devRTM_path\n",
    "\n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(devRTM_path)\n",
    "    for file in files:\n",
    "        if file.endswith(\".rttm\"):\n",
    "            file_path = os.path.join(devRTM_path, file)\n",
    "            rttm_data = parse_rttm(file_path)\n",
    "            rttm_data = prepare_data(rttm_data)\n",
    "            plot_timeline(rttm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Dataset/RTMS/Dev/afjiv.rttm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Get the MFCC and allign it with the RTM data for training --> Working\u001b[39;00m\n\u001b[0;32m     83\u001b[0m mfcc_test, sampling_rate \u001b[38;5;241m=\u001b[39m get_mfcc(path_wave)\n\u001b[1;32m---> 84\u001b[0m test_rttm_data \u001b[38;5;241m=\u001b[39m parse_rttm(path_rttm)\n\u001b[0;32m     85\u001b[0m test_rttm_data \u001b[38;5;241m=\u001b[39m prepare_data(test_rttm_data)\n\u001b[0;32m     86\u001b[0m test_alligned \u001b[38;5;241m=\u001b[39m align_mfcc(mfcc_test,sampling_rate,path_rttm)\n",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m, in \u001b[0;36mparse_rttm\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_rttm\u001b[39m(file_path):\n\u001b[0;32m     16\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile ID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignal Lookahead Time\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     ]\n\u001b[1;32m---> 28\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m, names\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurn Onset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurn Duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker Name\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\rakin\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Dataset/RTMS/Dev/afjiv.rttm'"
     ]
    }
   ],
   "source": [
    "# Get sampling rate of all audio files, allign mfcc with RTM data such that they can be used for training\n",
    "\n",
    "\n",
    "# Get the MFCC of the audio file using librosa\n",
    "def get_mfcc(file_path, hop_length=220):\n",
    "    \"\"\"\n",
    "    Compute the Mel-frequency cepstral coefficients (MFCC) for an audio file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the audio file.\n",
    "    hop_length (int): Number of samples between successive frames.\n",
    "\n",
    "    Returns:\n",
    "    mfcc (ndarray): The computed MFCC coefficients.\n",
    "    sr (int): The sample rate of the audio file.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=13, hop_length=hop_length\n",
    "    )  # Use consistent hop length\n",
    "    return mfcc, sr\n",
    "\n",
    "\n",
    "# Align the MFCC data with the RTM data -- Speaker segmentation for training\n",
    "def align_mfcc(mfcc_data, sr, rttm_path, hop_length=220):\n",
    "    \"\"\"\n",
    "    Aligns MFCC data with RTTM data using a specified hop length.\n",
    "\n",
    "    Args:\n",
    "        mfcc_data (numpy.ndarray): MFCC data.\n",
    "        sr (int): Sampling rate.\n",
    "        rttm_path (str): Path to the RTTM file.\n",
    "        hop_length (int, optional): Number of samples between successive frames. Defaults to 220.\n",
    "\n",
    "    Returns:\n",
    "        list of dicts: Each dictionary contains 'Speaker Name' and 'MFCC Segment'.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If required columns are missing in the DataFrame.\n",
    "    \"\"\"\n",
    "    rttm_data = parse_rttm(rttm_path)\n",
    "    rttm_data = prepare_data(rttm_data)\n",
    "\n",
    "    if \"End Time\" not in rttm_data.columns or \"Turn Onset\" not in rttm_data.columns:\n",
    "        raise KeyError(\"Necessary columns are missing from RTTM data.\")\n",
    "\n",
    "    # Convert RTTM times to frame indices\n",
    "    rttm_data[\"Start Frame\"] = (rttm_data[\"Turn Onset\"] * sr / hop_length).astype(int)\n",
    "    rttm_data[\"End Frame\"] = (rttm_data[\"End Time\"] * sr / hop_length).astype(int)\n",
    "\n",
    "    segments = []\n",
    "    num_frames = mfcc_data.shape[1]\n",
    "    audio_duration = num_frames * hop_length / sr\n",
    "    \n",
    "    for _, row in rttm_data.iterrows():\n",
    "        start_frame = row[\"Start Frame\"]\n",
    "        end_frame = row[\"End Frame\"]\n",
    "\n",
    "        # Clip start_frame and end_frame to valid range\n",
    "        start_frame = max(0, min(start_frame, num_frames - 1))\n",
    "        end_frame = max(0, min(end_frame, num_frames))\n",
    "\n",
    "        if start_frame >= end_frame:\n",
    "            print(\n",
    "                f\"Skipping segment with invalid frame range: Start Frame = {start_frame}, End Frame = {end_frame}\"\n",
    "            )\n",
    "            sys.exit(1)\n",
    "            continue\n",
    "\n",
    "        segment_mfcc = mfcc_data[:, start_frame:end_frame]\n",
    "        segments.append(\n",
    "            {\"Speaker Name\": row[\"Speaker Name\"], \"MFCC Segment\": segment_mfcc}\n",
    "        )\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Test get_mfcc on filepath\n",
    "path_wave = \"../Dataset/Audio/Dev/afjiv.wav\"\n",
    "path_rttm = \"../Dataset/RTMS/Dev/afjiv.rttm\"\n",
    "\n",
    "# Get the MFCC and allign it with the RTM data for training --> Working\n",
    "mfcc_test, sampling_rate = get_mfcc(path_wave)\n",
    "test_rttm_data = parse_rttm(path_rttm)\n",
    "test_rttm_data = prepare_data(test_rttm_data)\n",
    "test_alligned = align_mfcc(mfcc_test,sampling_rate,path_rttm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the entire dataset for training and testing\n",
    "Here we will go through all audio/dev wave files and extract the MFCC features and allign with the RTM data to create the final dataset for training and validation. Pick validation of 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [04:35<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to gather and align all data\n",
    "def get_training_and_validation(dev_audio_path, dev_RTM_path):\n",
    "    files = os.listdir(dev_audio_path)\n",
    "    all_data = []\n",
    "\n",
    "    for file in tqdm.tqdm(files):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(dev_audio_path, file)\n",
    "            rttm_path = os.path.join(dev_RTM_path, file.replace(\".wav\", \".rttm\"))\n",
    "            mfcc_data, sr = get_mfcc(file_path)\n",
    "            alligned_data = align_mfcc(mfcc_data, sr, rttm_path)\n",
    "            all_data.extend(alligned_data)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Gather all training data\n",
    "all_training_data = get_training_and_validation(\n",
    "    \"../Dataset/Audio/Dev/\", \"../Dataset/RTMS/Dev/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of loaded data: 8268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spk00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_in_chunks(data, directory, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Saves the list of segment dictionaries to multiple smaller files.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries containing 'Speaker Name' and 'MFCC Segment'.\n",
    "        directory (str): Path to the output directory.\n",
    "        chunk_size (int, optional): Number of items per chunk. Defaults to 1000.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i : i + chunk_size]\n",
    "        chunk_file_path = os.path.join(directory, f\"chunk_{i // chunk_size}.pkl\")\n",
    "        with open(chunk_file_path, \"wb\") as f:\n",
    "            pickle.dump(chunk, f)\n",
    "\n",
    "\n",
    "def load_chunks(directory):\n",
    "    \"\"\"\n",
    "    Loads the data from multiple smaller files.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing chunk files.\n",
    "\n",
    "    Returns:\n",
    "        list of dicts: Each dictionary contains 'Speaker Name' and 'MFCC Segment'.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    chunk_files = [\n",
    "        f\n",
    "        for f in os.listdir(directory)\n",
    "        if f.startswith(\"chunk_\") and f.endswith(\".pkl\")\n",
    "    ]\n",
    "    for chunk_file in sorted(chunk_files):\n",
    "        chunk_file_path = os.path.join(directory, chunk_file)\n",
    "        with open(chunk_file_path, \"rb\") as f:\n",
    "            chunk = pickle.load(f)\n",
    "            all_data.extend(chunk)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Store andLoad the data\n",
    "save_in_chunks(all_training_data, \"../Dataset/Audio/Dev_npz\", chunk_size=1000)\n",
    "loaded_data = load_chunks(\"../Dataset/Audio/Dev_npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
