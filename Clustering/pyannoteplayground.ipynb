{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=\"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\")\n",
    "diarization, embeddings = pipeline(\"../wav-files/4b.wav\", return_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33191782  0.12017356 -0.21278852 -0.0035682  -0.14905319  0.33943492\n",
      "  0.17680457 -0.18478882  0.15768221  0.38152137  0.00086053  0.31897414\n",
      "  0.37410823 -0.24575213  0.01352216  0.07771212  0.09743826  0.16467746\n",
      "  0.06073035  0.00298239 -0.06879069 -0.12528123 -0.05138676  0.14591888\n",
      "  0.42609584 -0.134773    0.19598025 -0.05553991 -0.11395623  0.04224063\n",
      "  0.1574573   0.13589676  0.43032372 -0.02420053 -0.12903498 -0.06768087\n",
      " -0.16334328 -0.2863768   0.31869838  0.05427642 -0.13413924 -0.22965384\n",
      " -0.01967582  0.23800495 -0.04720905  0.14934035  0.0864424  -0.17173754\n",
      " -0.15912783 -0.01271255 -0.01357703 -0.3754244   0.1497519  -0.20626143\n",
      "  0.17231083 -0.02306692  0.06042554 -0.02711732  0.26679975 -0.1847159\n",
      "  0.31595337 -0.20826438  0.06936674  0.02659851 -0.18852392 -0.08363135\n",
      " -0.0649899   0.28550622 -0.04408725 -0.07987702  0.20952877 -0.12178029\n",
      "  0.06191258  0.03758544  0.26111132 -0.17728792  0.38014355 -0.0939346\n",
      "  0.13260815  0.14776796 -0.09878066  0.3915056   0.21860145 -0.07798541\n",
      "  0.09015547  0.12752907  0.02470992 -0.14455448  0.1713903   0.0228223\n",
      "  0.24301293 -0.0526012   0.3108226   0.29066813  0.0667221   0.01946779\n",
      "  0.11801034  0.18459028 -0.15564667  0.31814843 -0.09843219 -0.12370816\n",
      " -0.03234497 -0.13228594 -0.26657996 -0.06063723 -0.15070984 -0.22905654\n",
      " -0.04892685 -0.08197123  0.21807733 -0.18135214 -0.320807   -0.01748921\n",
      "  0.2518825  -0.06000648 -0.07304284 -0.09472665  0.01586522  0.03042869\n",
      " -0.11720187 -0.28457704 -0.12055961 -0.12886165  0.12141708 -0.12528114\n",
      " -0.03587492  0.04448846  0.2549921   0.00925496  0.09046279 -0.13605276\n",
      "  0.06069334 -0.12426404  0.12902807 -0.1928364   0.0807687  -0.16496745\n",
      " -0.35572976  0.0546157   0.08791412 -0.06699279  0.06278087  0.23750463\n",
      " -0.16733313  0.18160114 -0.04415388 -0.3986236   0.2288065   0.04729272\n",
      "  0.07064386 -0.1500624   0.01260221 -0.3159316  -0.10355794  0.05906688\n",
      "  0.16109464 -0.07337627  0.04064035 -0.08882111 -0.49397498  0.27770174\n",
      "  0.12005766  0.11144587  0.0182604   0.16598795 -0.01245098 -0.11998094\n",
      " -0.06039092  0.10771725 -0.11058426  0.04875764  0.12319033  0.07838876\n",
      " -0.03909396 -0.34740904 -0.14210212  0.07921144 -0.3243549   0.15406306\n",
      " -0.0862464  -0.13101006 -0.4141072  -0.14016587 -0.1276232  -0.23038344\n",
      "  0.02277396 -0.08991182  0.06057983 -0.08287567  0.14794819 -0.1826246\n",
      " -0.5163777  -0.0357696  -0.08014591  0.21900228  0.24612485  0.3113017\n",
      "  0.07666397  0.0155732  -0.34210387  0.08431113  0.24881664 -0.06100827\n",
      "  0.08265202  0.17634854 -0.01331476 -0.17868926  0.34938258  0.00232288\n",
      " -0.22153997  0.12701325  0.430863   -0.04756236 -0.16139743 -0.05433707\n",
      " -0.19069742  0.06472649 -0.08636095 -0.06915648  0.17244618 -0.23785855\n",
      "  0.01877035 -0.23098196 -0.05805158 -0.30122012  0.14246677  0.01868804\n",
      "  0.24397415  0.01523983 -0.18068239  0.17656213  0.03527208  0.28875276\n",
      "  0.04255209 -0.00591227 -0.03194764  0.05465542 -0.20338468  0.09344323\n",
      "  0.07440911  0.00689326  0.01551735 -0.19025306  0.5287274   0.10785061\n",
      " -0.26007444  0.29771063 -0.06365558 -0.00606279  0.1746898  -0.04445496\n",
      "  0.02409748  0.08024892  0.1957285   0.10610222] is the embedding of speaker SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "# return embeddings of a speaker in a specific file\n",
    "for s, speaker in enumerate(diarization.labels()): \n",
    "    print(f\"{embeddings[s]} is the embedding of speaker {speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.1s stop=0.8s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "# return speaker's talking-time and time-stamps\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: either play with pyannote's Clustering module or take your embeddings and do clustering with them directly (if not too complicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "from pyannote.audio.pipelines.clustering import Clustering\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = Clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedPipeline(Pipeline):\n",
    "    def __init__(self, eps=0.5, min_samples=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Voice Activity Detection (VAD)\n",
    "        self.vad = Pipeline.from_pretrained(\n",
    "            \"pyannote/voice-activity-detection\",\n",
    "            use_auth_token=\"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\"\n",
    "        )\n",
    "\n",
    "        # Speaker Embedding Model\n",
    "        self.speaker_embedding = Model.from_pretrained(\n",
    "            \"pyannote/embedding\",\n",
    "            use_auth_token=\"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\"\n",
    "        )\n",
    "\n",
    "        # Binarize VAD scores with a 0.5 threshold.\n",
    "        self.binarize = Binarize(offset=0.52, onset=0.52, min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "        # Clustering using DBSCAN\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.clustering_algorithm = sklearn.cluster.DBSCAN(eps=self.eps, min_samples=self.min_samples)\n",
    "\n",
    "        # Diarization error rate\n",
    "        self.diarization_error_rate = {\"collar\": 0.0, \"skip_overlap\": False}\n",
    "\n",
    "    def apply(self, audio: dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.1.3 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\josep\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\059e96f964841d40f1a5e755bb7223f76666bba4\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.2.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.7.1, yours is 2.3.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "\n",
      "Could not download 'pyannote/embedding' model.\n",
      "It might be because the model is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Model.from_pretrained('pyannote/embedding',\n",
      "   ...                       use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the model is gated:\n",
      "visit https://hf.co/pyannote/embedding to accept the user conditions.\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = CustomizedPipeline(eps=0.5, min_samples=5)\n",
    "diarization = custom_pipeline(\"../wav-files/4b.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
