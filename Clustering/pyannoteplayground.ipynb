{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30936d86c76f4d189229df16390833f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec71d9e8a584418a6bc061fc196de14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fb42ffbac34ad49244882b8247134f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16f5f738bf34142914a289be0ba82b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6babc7c4636f4cc6837f6efb36b2819c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=\"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\")\n",
    "diarization, embeddings = pipeline(\"../wav-files/4b.wav\", return_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33191803  0.12017356 -0.21278872 -0.00356853 -0.14905289  0.33943504\n",
      "  0.17680483 -0.18478899  0.15768203  0.38152137  0.00086067  0.31897405\n",
      "  0.3741079  -0.24575205  0.01352201  0.07771251  0.09743816  0.16467702\n",
      "  0.06073016  0.00298271 -0.06879093 -0.12528084 -0.05138659  0.1459192\n",
      "  0.42609537 -0.1347725   0.19597952 -0.05554024 -0.11395615  0.04224091\n",
      "  0.15745816  0.13589656  0.43032378 -0.02420044 -0.12903495 -0.06768104\n",
      " -0.16334325 -0.28637654  0.31869876  0.05427608 -0.13413978 -0.22965352\n",
      " -0.01967614  0.23800512 -0.04720912  0.14934061  0.08644254 -0.1717369\n",
      " -0.15912788 -0.0127128  -0.01357657 -0.37542468  0.14975196 -0.20626087\n",
      "  0.17231059 -0.02306692  0.06042557 -0.02711708  0.26679948 -0.18471593\n",
      "  0.31595322 -0.20826437  0.06936681  0.02659812 -0.18852377 -0.08363116\n",
      " -0.06499039  0.28550637 -0.04408673 -0.07987736  0.2095289  -0.12178025\n",
      "  0.0619126   0.03758587  0.2611114  -0.1772875   0.38014352 -0.09393503\n",
      "  0.1326086   0.14776763 -0.09878021  0.39150575  0.21860132 -0.07798585\n",
      "  0.09015575  0.12752873  0.02470995 -0.1445547   0.1713902   0.0228224\n",
      "  0.24301273 -0.05260165  0.3108225   0.29066858  0.06672163  0.01946757\n",
      "  0.11801035  0.18458997 -0.15564665  0.31814858 -0.09843182 -0.12370846\n",
      " -0.03234509 -0.13228574 -0.2665802  -0.06063742 -0.15070984 -0.22905633\n",
      " -0.04892746 -0.08197131  0.21807733 -0.18135233 -0.32080716 -0.01748899\n",
      "  0.25188318 -0.06000574 -0.07304218 -0.09472646  0.01586511  0.03042861\n",
      " -0.11720219 -0.2845774  -0.12055925 -0.12886238  0.12141707 -0.12528083\n",
      " -0.03587561  0.04448822  0.25499222  0.00925502  0.09046262 -0.13605309\n",
      "  0.06069357 -0.12426391  0.12902871 -0.19283669  0.08076851 -0.16496713\n",
      " -0.35572967  0.05461537  0.08791461 -0.06699254  0.06278074  0.23750472\n",
      " -0.16733272  0.18160157 -0.04415394 -0.39862308  0.22880694  0.04729269\n",
      "  0.0706436  -0.15006231  0.01260207 -0.31593177 -0.10355805  0.05906687\n",
      "  0.16109474 -0.07337684  0.04064052 -0.08882153 -0.49397492  0.27770185\n",
      "  0.12005775  0.11144591  0.01826053  0.16598758 -0.01245116 -0.11998103\n",
      " -0.06039138  0.10771687 -0.11058398  0.04875724  0.12319041  0.07838868\n",
      " -0.03909373 -0.34740877 -0.14210248  0.07921156 -0.32435426  0.15406342\n",
      " -0.08624689 -0.13101062 -0.414107   -0.14016578 -0.12762335 -0.23038363\n",
      "  0.02277387 -0.08991189  0.06057939 -0.08287591  0.14794779 -0.18262465\n",
      " -0.5163772  -0.03576942 -0.08014562  0.21900208  0.24612515  0.3113014\n",
      "  0.07666354  0.01557322 -0.3421041   0.08431152  0.24881679 -0.0610088\n",
      "  0.08265185  0.17634797 -0.01331477 -0.17868897  0.34938252  0.00232333\n",
      " -0.22153994  0.12701347  0.43086287 -0.04756178 -0.1613981  -0.05433685\n",
      " -0.19069731  0.06472605 -0.08636095 -0.06915659  0.17244646 -0.23785877\n",
      "  0.01876991 -0.230982   -0.05805174 -0.30122012  0.14246705  0.01868838\n",
      "  0.24397416  0.01523951 -0.18068223  0.1765626   0.0352722   0.28875303\n",
      "  0.04255213 -0.00591244 -0.03194762  0.0546555  -0.20338471  0.0934431\n",
      "  0.07440881  0.00689327  0.0155173  -0.19025287  0.5287271   0.10785073\n",
      " -0.2600744   0.29771048 -0.06365526 -0.00606314  0.17468998 -0.04445487\n",
      "  0.02409828  0.08024902  0.19572854  0.10610222] is the embedding of speaker SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "# return embeddings of a speaker in a specific file\n",
    "for s, speaker in enumerate(diarization.labels()): \n",
    "    print(f\"{embeddings[s]} is the embedding of speaker {speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.1s stop=0.8s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "# return speaker's talking-time and time-stamps\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: either play with pyannote's Clustering module or take your embeddings and do clustering with them directly (if not too complicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "from pyannote.audio.pipelines.clustering import Clustering\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = Clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedPipeline(Pipeline):\n",
    "    def __init__(self, eps=0.5, min_samples=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Voice Activity Detection (VAD)\n",
    "        self.vad = Pipeline.from_pretrained(\n",
    "            \"pyannote/voice-activity-detection\",\n",
    "            use_auth_token=\"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\"\n",
    "        )\n",
    "\n",
    "        # Speaker Embedding Model\n",
    "        self.speaker_embedding = Model.from_pretrained(\n",
    "            \"pyannote/embedding\",\n",
    "            use_auth_token=\"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\"\n",
    "        )\n",
    "\n",
    "        # Binarize VAD scores with a 0.5 threshold.\n",
    "        self.binarize = Binarize(offset=0.52, onset=0.52, min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "        # Clustering using DBSCAN\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.clustering_algorithm = sklearn.cluster.DBSCAN(eps=self.eps, min_samples=self.min_samples)\n",
    "\n",
    "        # Diarization error rate\n",
    "        self.diarization_error_rate = {\"collar\": 0.0, \"skip_overlap\": False}\n",
    "\n",
    "    def apply(self, audio: dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.1.3 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\josep\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\059e96f964841d40f1a5e755bb7223f76666bba4\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.2.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.7.1, yours is 2.3.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "\n",
      "Could not download 'pyannote/embedding' model.\n",
      "It might be because the model is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Model.from_pretrained('pyannote/embedding',\n",
      "   ...                       use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the model is gated:\n",
      "visit https://hf.co/pyannote/embedding to accept the user conditions.\n"
     ]
    }
   ],
   "source": [
    "custom_pipeline = CustomizedPipeline(eps=0.5, min_samples=5)\n",
    "diarization = custom_pipeline(\"../wav-files/4b.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
